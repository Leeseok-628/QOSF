{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST datasets from Keras\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#Rescale the images from [0, 255] to the [0.0, 1.0] range.\n",
    "train_images, test_images = train_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_tf0 = np.where(train_labels == 0)\n",
    "train_filter_tf1 = np.where(train_labels == 1)\n",
    "\n",
    "train_images_tf0, train_labels_tf0 = train_images[train_filter_tf0], train_labels[train_filter_tf0]\n",
    "\n",
    "train_images_tf1, train_labels_tf1 = train_images[train_filter_tf1], train_labels[train_filter_tf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter_tf = np.where((train_labels == 0 ) | (train_labels == 1 )| (train_labels == 2 )\n",
    "                          | (train_labels == 3 )| (train_labels == 4 )| (train_labels == 5 )\n",
    "                          | (train_labels == 6 )| (train_labels == 7 ))\n",
    "test_filter_tf = np.where((test_labels == 0 ) | (test_labels == 1 )| (test_labels == 2 )\n",
    "                         | (test_labels == 3 )| (test_labels == 4 )| (test_labels == 5 )\n",
    "                         | (test_labels == 6 )| (test_labels == 7 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tf, train_labels_tf = train_images[train_filter_tf], train_labels[train_filter_tf]\n",
    "test_images_tf, test_labels_tf = test_images[test_filter_tf], test_labels[test_filter_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_tf = keras.utils.to_categorical(train_labels_tf, num_classes-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 12808     \n",
      "=================================================================\n",
      "Total params: 31,624\n",
      "Trainable params: 31,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes-2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3024 - accuracy: 0.9098 - val_loss: 0.0547 - val_accuracy: 0.9857\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 17s 49ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 0.0411 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 13s 39ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 0.0371 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 17s 50ms/step - loss: 0.0490 - accuracy: 0.9848 - val_loss: 0.0317 - val_accuracy: 0.9923\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 15s 43ms/step - loss: 0.0426 - accuracy: 0.9866 - val_loss: 0.0313 - val_accuracy: 0.9927\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 15s 46ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.0270 - val_accuracy: 0.9929\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.0362 - accuracy: 0.9888 - val_loss: 0.0247 - val_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.0262 - val_accuracy: 0.9936\n",
      "Epoch 9/10\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.0248 - val_accuracy: 0.9938\n",
      "Epoch 10/10\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0237 - val_accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f2d95c0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images_tf, train_labels_tf, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = keras.Model(inputs=model.inputs,\n",
    "                        outputs=[layer.output for layer in model.layers])\n",
    "features0 = extractor(train_images_tf0)\n",
    "features1 = extractor(train_images_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = np.array(tf.constant(features0[6]))\n",
    "X_train_1 = np.array(tf.constant(features1[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = X_train_0[:100]\n",
    "X_train_1 = X_train_1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-scale \n",
    "def rescale_linear(array, new_min, new_max):\n",
    "    \"\"\"Rescale an arrary linearly.\"\"\"\n",
    "    minimum, maximum = np.min(array), np.max(array)\n",
    "    m = (new_max - new_min) / (maximum - minimum)\n",
    "    b = new_min - m * minimum\n",
    "    return m * array + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9996591e-01, 1.6879586e-11, 2.8085671e-05, 9.0969227e-10,\n",
       "       8.4807725e-09, 3.9191441e-08, 5.9049908e-06, 5.2797532e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.2606166e-07, 9.9975532e-01, 6.5584121e-05, 5.5110820e-07,\n",
       "       1.7101977e-04, 4.0437637e-08, 9.6511599e-07, 5.6995118e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.4107991e-07 1.5707964e+00 1.9779854e-05 1.0654456e-07 1.2680655e-04\n",
      " 0.0000000e+00 8.3861460e-06 5.7085465e-05]\n"
     ]
    }
   ],
   "source": [
    "print(rescale_linear(X_train_1[0], 0, np.pi/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0722359e-07, 9.9989200e-01, 2.2830254e-05, 4.4897016e-07,\n",
       "       6.7050292e-05, 5.4192692e-06, 9.1852326e-07, 1.1257809e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Dataset\n",
    "X_train_0_f = []\n",
    "X_train_1_f = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train_0_f.append(rescale_linear(X_train_0[i], 0, np.pi/2))\n",
    "    X_train_1_f.append(rescale_linear(X_train_1[i], 0, np.pi/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_0_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_0_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wires = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_encoding(vector):\n",
    "    for i in range(num_wires):\n",
    "        qml.RY(vector[i]*2, wires=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_block_t(params, wires):\n",
    "    \"\"\"\n",
    "    2 qubit block representing U(D) blocks in the paper that has control wire on the top wire\n",
    "    \"\"\"\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_block_b(params, wires):\n",
    "    \"\"\"\n",
    "    2 qubit block represetning U(D) blocks in the paper that has control wire is on the bottom wire\n",
    "    \"\"\"\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1],wires[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "qml.enable_tape()\n",
    "dev1 = qml.device('default.qubit', wires=num_wires)\n",
    "\n",
    "@qml.qnode(dev1, diff_method=\"backprop\")\n",
    "def variational_circuit(params, features):\n",
    "    #qubit_encoding\n",
    "    qubit_encoding(features)\n",
    "    \n",
    "    #MERA circuit\n",
    "    #D blocks on (1,2), (3,4), (5,6), (7,8)    \n",
    "    U_block_t(params[:2],wires=[1,2])\n",
    "    U_block_b(params[2:4],wires=[3,4])\n",
    "    U_block_t(params[4:6],wires=[5,6])\n",
    "    #U_block_t(params[6:8],wires=[7,8])\n",
    "\n",
    "    #U blocks on (0,1), (2,3), (4,5), (6,7), (8,9)\n",
    "    U_block_t(params[6:8],wires=[0,1])\n",
    "    U_block_d(params[8:10],wires=[2,3])\n",
    "    U_block_t(params[10:12],wires=[4,5])\n",
    "    U_block_d(params[12:14],wires=[6,7])\n",
    "    #U_block_d(params[:2],wires=[1,2])\n",
    "    \n",
    "    #D in the middle\n",
    "    U_block_t(params[14:16],wires=[2,5])\n",
    "    \n",
    "    #Two U's\n",
    "    U_block_t(params[16:18],wires=[1,2])\n",
    "    U_block_d(params[18:20],wires=[5,6])\n",
    "    \n",
    "    #Last U\n",
    "    U_block_t(params[20:22],wires=[2,5])\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def cost(var, X, Y):\n",
    "    predictions = [variational_circuit(var, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_0_f + X_train_1_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_labels_tf0[:100].tolist() + train_labels_tf1[:100].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46344729527647344\n",
      "0.21083671441965599\n",
      "0.21371911430833496\n",
      "0.13615002634894263\n",
      "0.04589539069405711\n",
      "0.015281679230924891\n",
      "0.0037935259792574462\n",
      "0.010990378215842832\n",
      "0.012320800483042476\n",
      "0.013614789424986447\n",
      "0.0073969691970388555\n",
      "0.004554985284519623\n",
      "0.007493186547530952\n",
      "0.002329906481891377\n",
      "0.0023732308383424363\n",
      "0.0021002160885410363\n",
      "0.0010128128343910305\n",
      "0.0011539128563409396\n",
      "0.0009829709065186669\n",
      "0.0009481901009537665\n",
      "0.0012725030981922713\n",
      "0.0012168343621481018\n",
      "0.0012330197671389174\n",
      "0.0020099544451545833\n",
      "0.0014222170335035124\n",
      "0.0010134665035070756\n",
      "0.0014747898340482111\n",
      "0.0008785614531273122\n",
      "0.0009441842247379939\n",
      "0.0009232987228231957\n",
      "0.0006445090539631438\n",
      "0.0006393413878367942\n",
      "0.0011862795487816546\n",
      "0.0013555296413589348\n",
      "0.00047378369162995125\n",
      "0.0009636250885353609\n",
      "0.00013944673575877996\n",
      "0.00019542178637506469\n",
      "0.00018072310170021036\n",
      "0.0002041584421871986\n",
      "0.0001312843240345654\n",
      "8.218577446501196e-05\n",
      "0.00011272309686164101\n",
      "0.0008344564992297784\n",
      "0.00038159361314585365\n",
      "8.939419193659715e-05\n",
      "0.00014322191244923736\n",
      "0.00011022952614959693\n",
      "0.00011458480385648974\n",
      "0.000346893219267188\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "var_init = np.random.randn(22)\n",
    "\n",
    "opt = qml.NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 20\n",
    "\n",
    "#optimization\n",
    "var = var_init\n",
    "for it in range(50):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "    X_batch = [X_train[i] for i in batch_index]\n",
    "    Y_batch = [Y_train[i] for i in batch_index]\n",
    "    var, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch), var)\n",
    "    print(cost_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799,\n",
       "       -0.97727788,  0.95008842, -0.15135721, -0.10321885,  0.4105985 ,\n",
       "        0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
       "        0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574,\n",
       "       -2.55298982,  0.6536186 ])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.97691224, -1.14761573,  0.7780793 ,  2.99357889,  2.33036416,\n",
       "        -0.7489642 ,  0.93982075,  0.07013816,  0.82772584,  0.85359053,\n",
       "         0.27173761,  1.35890477,  0.64816301, -0.00724718, -0.16305724,\n",
       "         1.11857802,  1.60143486, -1.96183988,  0.08322165, -0.98074687,\n",
       "        -2.30456912,  0.86276042], requires_grad=True)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X_test\n",
    "test_filter_tf0 = np.where(test_labels == 0)\n",
    "test_filter_tf1 = np.where(test_labels == 1)\n",
    "\n",
    "test_images_tf0, test_labels_tf0 = test_images[test_filter_tf0], test_labels[test_filter_tf0]\n",
    "\n",
    "test_images_tf1, test_labels_tf1 = test_images[test_filter_tf1], test_labels[test_filter_tf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "features0_test = extractor(test_images_tf0)\n",
    "features1_test = extractor(test_images_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0 = np.array(tf.constant(features0_test[6]))\n",
    "X_test_1 = np.array(tf.constant(features1_test[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0 = X_train_0[:100]\n",
    "X_test_1 = X_train_1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Test Dataset\n",
    "X_test_0_f = []\n",
    "X_test_1_f = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_test_0_f.append(rescale_linear(X_test_0[i], 0, np.pi/2))\n",
    "    X_test_1_f.append(rescale_linear(X_test_1[i], 0, np.pi/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_0_f + X_test_1_f\n",
    "Y_test = test_labels_tf0[:100].tolist() + test_labels_tf1[:100].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_results=[]\n",
    "for x in X_test:\n",
    "    #print(variational_classifier(var,x))\n",
    "    if 0.5 > np.abs(variational_classifier(var, x)):\n",
    "        label_results.append(0)\n",
    "    else:\n",
    "        label_results.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(label_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
